{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class PCA:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.components = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        finds best params for X = Mu + A * Lambda\n",
    "        :param data: data of shape (number of samples, number of features)\n",
    "        HINT! use SVD\n",
    "        \"\"\"\n",
    "        _,s,v = np.linalg.svd(data)\n",
    "        eigenvalues = np.diagonal(s)**2\n",
    "        biggest_indices = eigenvalues.argsort()[-self.k:][::-1]\n",
    "        self.components = v[biggest_indices]\n",
    "        \n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        for given data returns Lambdas\n",
    "        x_i = mu + A dot lambda_i\n",
    "        where mu is location_, A is matrix_ and lambdas are projection of x_i\n",
    "        on linear space from A's rows as basis\n",
    "        :param data: data of shape (number of samples, number of features)\n",
    "        \"\"\"\n",
    "        # Lemma: x is vector and A dot A.T == I, then x's coordinates in Linear Space(A's rows as basis)\n",
    "        # is A dot x\n",
    "        lambdas = np.dot(self.new_basis, data.T).T\n",
    "        return lambdas\n",
    "    \n",
    "    def return_components(self):\n",
    "        return self.components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "This is a boilerplate file for you to get started on MNIST dataset and run SVD.\n",
    "\n",
    "This file has code to read labels and data from .gz files you can download from\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Files will work if train-images-idx3-ubyte.gz file and\n",
    "train-labels-idx1-ubyte.gz files are in the same directory as this\n",
    "python file.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PCA import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def parse_args(*argument_array):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--mnist-train-data',\n",
    "                        default='train-images-idx3-ubyte.gz',  # noqa\n",
    "                        help='Path to train-images-idx3-ubyte.gz file '\n",
    "                        'downloaded from http://yann.lecun.com/exdb/mnist/')\n",
    "    parser.add_argument('--mnist-train-labels',\n",
    "                        default='train-labels-idx1-ubyte.gz',  # noqa\n",
    "                        help='Path to train-labels-idx1-ubyte.gz file '\n",
    "                        'downloaded from http://yann.lecun.com/exdb/mnist/')\n",
    "    args = parser.parse_args(*argument_array)\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # Read data file into numpy matrices\n",
    "    with gzip.open(args.mnist_train_data, 'rb') as in_gzip:\n",
    "        magic, num, rows, columns = struct.unpack('>IIII', in_gzip.read(16))\n",
    "        all_data = np.array([np.array(struct.unpack('>{}B'.format(rows * columns),\n",
    "                                           in_gzip.read(rows * columns)))\n",
    "                    for _ in range(6000)])\n",
    "    with gzip.open(args.mnist_train_labels, 'rb') as in_gzip:\n",
    "        magic, num = struct.unpack('>II', in_gzip.read(8))\n",
    "        all_labels = struct.unpack('>6000B', in_gzip.read(6000))\n",
    "    each_label = np.empty(10, dtype = object)\n",
    "    for i in range(10):\n",
    "        each_label[i] = all_data[np.array(all_labels) == i]\n",
    "    pca = PCA(5)\n",
    "    pca.fit(all_data)\n",
    "    all_data_transform = pca.transform(all_data)\n",
    "    kmeans_labels = KMeans(n_clusters=10, random_state=0).fit_predict(all_data)\n",
    "    each_cluster = np.empty(10, dtype = object)\n",
    "    for i in range(10):\n",
    "        each_cluster[i] = all_data_transform[:,:2][np.array(kmeans_labels) == i]\n",
    "    f, axarr = plt.subplots(2, 10, figsize=(18, 4), sharey=True)\n",
    "    for i in range(10):\n",
    "        a = pca.transform(each_label[i])\n",
    "        axarr[0][i].scatter(a.T[0], a.T[1], s = 1)\n",
    "    for i in range(10):\n",
    "        axarr[1][i].scatter(each_cluster[i].T[0], each_cluster[i].T[1], s = 1)\n",
    "    plt.show()\n",
    "    coincidence_matrix = np.zeros((10,10)).astype(int)\n",
    "    for i in range(6000):\n",
    "        coincidence_matrix[all_labels[i], kmeans_labels[i]]+=1\n",
    "    print(coincidence_matrix)\n",
    "    #plt.savefig(\"labels_vs_kmeans_clusters.jpg\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
